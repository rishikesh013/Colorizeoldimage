# Colorizeoldimage
This is an Simple code which colorizes the the old black and white photo

Image colorization is a fascinating and challenging topic in image-to-image translation. Colorization is a process of converting grayscale images into visually acceptable color images. Many cameras, such as surveillance cameras and satellite cameras, still capture grayscale images which is kind of hard to analyse the image. In this project, we built an image colorization framework based on a deep learning method known as Generative Adversarial Networks, or GANs for short. GANs are a type of generative modelling that employs deep learning techniques such as convolutional neural networks.

###Wroking of the model:
  This is a new sort of GAN training that We have created to address several critical issues in the prior image colorization models. It gives the benefits of GAN training while requiring less direct GAN training. Instead, the majority of the training time is spent separately pretraining the generator and discriminator using more straightforward, rapid, and reliable conventional approaches. A fundamental finding here is that more "traditional" approaches often produce the majority of the results required, and that GANs can be used to bridge the realism gap.
	The generator not only achieves the complete realistic colorization capabilities that used to take days of increasingly resized GAN training, but it also doesn't accumulate nearly as much of the artefacts and other unpleasant baggage of GANs. In fact, depending on the approach, it can almost entirely eradicate glitches and artefacts. This new technology is extremely adaptable and efficient.
	The procedure is as follows: First, train the generator conventionally using only the feature loss. Next, build images from that and train the critic as a basic binary classifier to discriminate between those outputs and real photos. Finally, in a GAN scenario, train the generator and critic jointly (starting right at the target size of 192px in this case). All of the useful GAN training here takes place in a relatively short period of time. There appears to be a tipping point where the critic has transferred everything it can that is beneficial to the generator. After this moment, image quality oscillates between the best that can be obtained at the inflection point and the worst that can be obtained in a predictable manner (orangish skin, overly red lips, etc). Following the inflection point, there appears to be no productive training. And this stage is reached after training on about 1% to 3% of Imagenet data! This equates to 30-60 minutes of training at 192px.
	The difficult thing is determining this inflection moment. So far, we have done this by creating lots of new model save checkpoints (every 0.1 percent of data iterated on) and then simply looking for the point when photographs look excellent before going completely insane with orange skin (always the first thing to go). Furthermore, generator rendering becomes quickly glitchy and unpredictable at this stage, which is not desirable, especially for photo. 
	Another important aspect of this kind of training is that you can pretrain the critic on created images after the initial GAN training, then redo the GAN training itself in the same manner. This is how we were able to achieve such vibrant outcomes with the "artistic" model. However, this comes at a cost right now: the generator's output becomes progressively erratic, and you must experiment with render resolution (render-factor) to get the optimal outcome. However, the renders are still devoid of flaws and far more consistent than I was able to produce with the original Image colorization model. As far as I can determine, you can do approximately five of these repeat cycles before you start seeing decreasing returns.


To work with the model:
  1. Clone the repository to your local machine
  2. Install the requirements.txt with the command pip install -r requirements.txt
  3. Download the model from the link [click here for model](https://bit.ly/3KQd7iH)
  4. Place the models folder inside the main colorizeoldimage
  5. Run the program ImageColorizer.py in jupyter notebook
